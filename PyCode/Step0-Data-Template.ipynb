{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Useful functions:\n",
      "1. convert2Categ(df, threshold=5): to convert all category variables to dummy columns\n",
      "2. flat2String(arg): to flattening arbitrary levels.\n",
      "3. binary_perform(actual, pred): to print out binary classification performance.\n"
     ]
    }
   ],
   "source": [
    "#%run \"/Users/x644435/Documents/Good2Know/PythonLearn/Useful/UsefulFunc.py\"\n",
    "%run /nfs/science/users/xiaojiez/Python/UsefulPyFunc.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### set up working path\n",
      "Current Working Directory: /nfs/science/users/xiaojiez \n",
      "List of Files: ['Step0-Data-Template.ipynb', 'LCM', '.ipynb_checkpoints', 'Source', 'set_proxy_script.txt', 'FeatureRep', 'Learn', 'Rcode', 'Python', 'Junk', 'Shannon', 'TS', 'Churn', 'from_0199']\n"
     ]
    }
   ],
   "source": [
    "### Save to a python script\n",
    "# !jupyter nbconvert  Step0-Data.ipynb --to script\n",
    "\n",
    "\n",
    "#Import popular libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "### Set up display options\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 300) # maximum display width \n",
    "pd.set_option('display.max_colwidth',120)\n",
    "\n",
    "import os\n",
    "\n",
    "print '### set up working path'\n",
    "currpath = \"/nfs/science/users/xiaojiez\"\n",
    "os.chdir(currpath)\n",
    "print 'Current Working Directory:', os.getcwd(), '\\n', 'List of Files:', os.listdir(currpath)\n",
    "# os.remove(path)  # remove a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read/write feather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import feather\n",
    "path = 'my_data.feather'\n",
    "feather.write_dataframe(df, path)\n",
    "df = feather.read_dataframe(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load R data into Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import rpy2.robjects as robjects\n",
    "import pandas as pd\n",
    "\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects import r\n",
    "\n",
    "robjects.r['load'](\"Q20152DM.RData\")\n",
    "\n",
    "df = pandas2ri.ri2py(r['Q20152DM'])\n",
    "df =  pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../Data/VALUE_P_TRAIN.csv')\n",
    "print df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read SAS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/x644435/Documents/Good2Know/PythonLearn/sas7bdat-2.0.7/\")\n",
    "from sas7bdat import SAS7BDAT\n",
    "\n",
    "# foo1 = SAS7BDAT('/Users/x644435/Documents/MOO/LCM-Digital/Data/ip_redc_vars.sas7bdat')\n",
    "# df1 = foo1.to_data_frame()\n",
    "# df1\n",
    "\n",
    "# foo2 = SAS7BDAT('/Users/x644435/Documents/MOO/LCM-Digital/Data/temp.sas7bdat')\n",
    "# df2 = foo2.to_data_frame()\n",
    "\n",
    "# concatenate them horizontally\n",
    "# frames = [df2, df1]\n",
    "# df = pd.concat(frames,axis=1)\n",
    "# df = df.drop(df.columns[[2,3,4,5,6,7,8,9,10]],1)\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read/write hdf5 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# store = pd.HDFStore('ip_redc_vars_9_13_2016.h5', mode='w')\n",
    "# store['df1'] = df1  # save it\n",
    "# store.close()\n",
    "# df1.dtypes\n",
    "\n",
    "store_r = pd.HDFStore('/Users/x644435/Documents/MOO/LCM-Digital/Python/ip_redc_vars_9_13_2016.h5', mode='r')\n",
    "\n",
    "df = store_r['df1']  # load it\n",
    "print 'Original df.shape:', df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get columns with levels 5 or less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Col5less = pd.DataFrame([[col, df[col].dtype, len(df[col].unique())] for col in df.columns if len(df[col].unique()) <= 5], columns=['Colnames','DataType', 'nLevels'])\n",
    "Col5less = Col5less.sort(['nLevels'])\n",
    "\n",
    "print 'Columns with less than 5 distinct levels:\\n', Col5less"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a list with 1 level and drop off from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RemoveList = Col5less[Col5less['nLevels']<=1][[0]].values.tolist()  # add column names with 1 level\n",
    "RemoveList += ['HOUSEHOLD_ID','train']\n",
    "RemoveList = list(str(RemoveList).translate(None,\"[]u' \").split(','))\n",
    "print '\\n Columns with only 1 level + others, to be removed:\\n', RemoveList\n",
    "\n",
    "#drop columns\n",
    "df.drop(RemoveList, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove features with low variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "X = pd.DataFrame([[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1]])\n",
    "X.columns=['A','B','C']\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "print X, '\\n', sel.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create dummylist\n",
    "Clist = list(df.select_dtypes(include=['O']).columns) #get all categorical columns\n",
    "dummyList=Clist+['segment']\n",
    "print \"Dummifiy columns:\", dummyList\n",
    "\n",
    "df = pd.get_dummies(df, columns=dummyList, drop_first=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if there are any non-float columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Check non-float columns:', len(list (df.select_dtypes(exclude=['float']).columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if there are any more missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NoMissing = df.isnull().sum()\n",
    "NoMissing = NoMissing[NoMissing>0]\n",
    "\n",
    "print 'Columns with non-zero missing data:\\n\\n', NoMissing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract a list of variables with certain prefix and apply log10+1 transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recode_tmp  = [col for col in Cfeatures.columns if 'CPRE_NBSKTS' in col] +\\\n",
    "              [col for col in Cfeatures.columns if 'CPRE_SALE' in col]\n",
    "\n",
    "Cfeatures[recode_tmp] = Cfeatures[recode_tmp].applymap(lambda x: np.log10(x+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, Xc_train, Xc_test, Xh_train, Xh_test, \\\n",
    "y_train, y_test,  = train_test_split(X, Xc, Xh, y, train_size=0.8, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Variable rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "MinMax = MinMaxScaler(feature_range=(0, 1))\n",
    "STD = StandardScaler(with_std=False)\n",
    "pipe = Pipeline(steps=[('MinMax', MinMax), ('STD', STD)])\n",
    "\n",
    "\n",
    "X_train = pipe.fit_transform(X_train)\n",
    "X_test = pipe.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rescale a list of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recode  = [col for col in Cfeatures.columns if 'CPRE_NBSKTS' in col] +\\\n",
    "              [col for col in Cfeatures.columns if 'CPRE_SALE' in col]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "X_train[to_recode] = scaler.fit_transform(X_train[to_recode])\n",
    "X_test[to_recode] = scaler.transform(X_test[to_recode])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27base]",
   "language": "python",
   "name": "conda-env-py27base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
